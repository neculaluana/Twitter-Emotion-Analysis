{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/neculaluana/Twitter-emotion-analysis/blob/main/emotion_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "i8U9jQtfR7In"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import torch\n",
        "import plotly.express as px\n",
        "\n",
        "from google.colab import drive\n",
        "from datasets import Dataset, DatasetDict, Features, Value, ClassLabel\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from transformers import DataCollatorWithPadding\n",
        "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
        "from transformers import pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_train = pd.read_csv('https://raw.githubusercontent.com/neculaluana/Twitter-emotion-analysis/main/input/training.csv?token=GHSAT0AAAAAACBUYC47QMRBYGX5L5L7H6FGZCBAPEA')\n",
        "df_test = pd.read_csv('https://raw.githubusercontent.com/neculaluana/Twitter-emotion-analysis/main/input/test.csv?token=GHSAT0AAAAAACBUYC477ZGWJ43J7OLYWPVGZCBAM7Q')\n",
        "df_valid = pd.read_csv('https://raw.githubusercontent.com/neculaluana/Twitter-emotion-analysis/main/input/validation.csv?token=GHSAT0AAAAAACBUYC47FCWVRUS45ZFJAQOYZCBAQDA')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCjElxq2R_Uu",
        "outputId": "9c2393a9-d6ce-4185-e52b-86593133ad11"
      },
      "outputs": [],
      "source": [
        "def clean_tweet(tweet):\n",
        "\n",
        "  tweet = re.sub(r'https?://[^ ]+', '', str(tweet))      #removes links\n",
        "  tweet = re.sub(r'@[^ ]+', '', str(tweet))              #removes mentions\n",
        "  tweet = re.sub(r'#', '', str(tweet))                   #removes hashtag symbol\n",
        "  tweet = re.sub(r'([A-Za-z])\\1{2,}', r'\\1', str(tweet)) #removes repeated characters ex: heeeeeeey\n",
        "  tweet = re.sub(r'[^A-Za-z ]', '', str(tweet))          #removes unwanted characters and punctuation\n",
        "  tweet = re.sub(r' 0 ', 'zero', str(tweet))             #transforms 0 to zero (it can influence emotion)\n",
        "  tweet = tweet.lower()                                  #lower-casing\n",
        "  return tweet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oXnTyAaFe7yE"
      },
      "outputs": [],
      "source": [
        "df = pd.concat([df_train, df_valid, df_test], ignore_index=True, sort=False)\n",
        "df[\"text\"]=df[\"text\"].apply(lambda text: clean_tweet(text))\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "emotion_names = ['sadness', 'joy', 'love', 'anger', 'fear', 'surprise']\n",
        "custom_features = Features({\n",
        "    'text': Value(dtype='string'),\n",
        "    'label': ClassLabel(names=emotion_names)\n",
        "})\n",
        "\n",
        "\"\"\"emotions_full = DatasetDict({\n",
        "    \"train\": Dataset.from_pandas(df_train,features=custom_features),\n",
        "    \"test\": Dataset.from_pandas(df_test,features=custom_features),\n",
        "    \"validation\": Dataset.from_pandas(df_valid,features=custom_features)\n",
        "    })\n",
        "\n",
        "\"\"\"\n",
        "emotions_full_dataset = Dataset.from_pandas(df, features=custom_features)\n",
        "data_column=emotions_full_dataset [\"text\"]\n",
        "label_column=emotions_full_dataset [\"label\"]\n",
        "\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(data_column, label_column, test_size=0.4, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_train, y_train, test_size=0.5, random_state=42)\n",
        "\n",
        "dataset = DatasetDict({\"train\": Dataset.from_dict({\"text\": X_train, \"label\": y_train}),\n",
        "                        \"validation\": Dataset.from_dict({\"text\": X_val, \"label\": y_val}),\n",
        "                        \"test\": Dataset.from_dict({\"text\": X_test, \"label\": y_test})})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "def tokenize(batch):\n",
        "    return tokenizer(batch['text'], padding=True, truncation=True)\n",
        "\n",
        "tokenized_datasets = dataset.map(tokenize, batched=True, batch_size=None)\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "drive.mount('/content/gdrive')\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=6).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir='/content/gdrive/MyDrive/EmotionAnalysis/checkpoints60',          # output directory\n",
        "    num_train_epochs=3, # total number of training epochs\n",
        "    learning_rate=2e-5,             # learning rate\n",
        "    per_device_train_batch_size=64,  # batch size per device during training\n",
        "    per_device_eval_batch_size=64,   # batch size for evaluation\n",
        "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
        "    weight_decay=0.01,               # strength of weight decay\n",
        "    logging_dir='/content/gdrive/MyDrive/EmotionAnalysis/logs60',            # directory for storing logs\n",
        "    logging_steps=10,             # log saving step\n",
        "    save_total_limit=1,             # number of total save model\n",
        "    load_best_model_at_end=True,    # load the best model when finished training (default metric is loss)\n",
        "    metric_for_best_model=\"accuracy\",   # use accuracy when comparing two models\n",
        "    greater_is_better=True,            # higher metric value is better\n",
        "    evaluation_strategy=\"epoch\",    # evaluate each `logging_steps`\n",
        "    save_strategy=\"epoch\",        # save each `logging_steps`\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
        "    accuracy = accuracy_score(labels, preds)\n",
        "    return {\"accuracy\": accuracy, \"f1\": f1}\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "trainer.train()\n",
        "trainer.save_model('/content/gdrive/MyDrive/EmotionAnalysis/models60')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "result_eval=trainer.evaluate(tokenized_datasets[\"test\"])\n",
        "print(result_eval)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "drive.mount('/content/gdrive')\n",
        "\n",
        "classifier = pipeline(\"text-classification\", model=\"/content/gdrive/MyDrive/EmotionAnalysis/models60\", tokenizer=DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#prediction for one tweet\n",
        "emotion_names = ['sadness', 'joy', 'love', 'anger', 'fear', 'surprise']\n",
        "predict_emotions = classifier(\"I can't believe someone would do such a thing\", return_all_scores=True)\n",
        "emotion_mapping = {\n",
        "    'LABEL_0': 'sadness',\n",
        "    'LABEL_1': 'joy',\n",
        "    'LABEL_2': 'love',\n",
        "    'LABEL_3': 'anger',\n",
        "    'LABEL_4': 'fear',\n",
        "    'LABEL_5': 'surprise'\n",
        "}\n",
        "#for prediction in predict_emotions:\n",
        "    #prediction[0] = emotion_mapping[prediction[\"label\"]]\n",
        "print(predict_emotions)\n",
        "\n",
        "df_preds = pd.DataFrame.from_records(predict_emotions[0])\n",
        "px.bar(x=emotion_names,y=100*df_preds['score'],template='plotly_white')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyP6PyW90UkFOxzGyWsOqhnu",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
